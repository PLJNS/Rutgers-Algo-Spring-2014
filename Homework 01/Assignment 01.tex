\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, graphics, setspace}
\usepackage[noline,noend,ruled,linesnumbered]{algorithm2e}
\usepackage{algpseudocode}

\newcommand{\mathsym}[1]{{}}
\newcommand{\unicode}[1]{{}}

\title{Assignment 01}

\author{Paul Jones and Matthew Klein \\
		Professor Professor Kostas Bekris\\
		Design and Analysis of Computer Algorithms (01.198.344)}

\date{\today}

\usepackage{setspace}
\singlespacing

\begin{document}

\maketitle

\pagebreak

\section*{Part A}

\subsection*{Problem 1}

In each of the following situations indicate whether $f = O(g)$ or $f = \Omega(g)$ 
or $f = \Theta(g)$:

\begin{enumerate}

	\item $f(n) = \sqrt{2^{7x}}, g(n) = \lg(7^{2x})$
		
		\[ f(n) = \sqrt{2^{7x}} = \sqrt{128^{x}}\]
		\[ g(n) = \lg(7^{2x}) = \lg(49^{x})\]
		\[ lg(49^1) \approx 5.6 \]
		\[ \sqrt{128^{1}} \approx 11.3 \]
		
		Notice that both of these functions only grow relative to $x$.
		
		\[ f = \Omega(g) \]
	
	\item $f(n) = 2^{nln(n)}, g(n) = n!$
	
		The factorial, that is $n!$, function grows much, much faster than $2^n$.
		
		\[ f = \Omega(g) \]
	
	\item $f(n) = \lg(\lg^*(n)), g(n) = \lg^*(\lg(n)) $
	
		\[ f = \Theta(g) \]
	
	\item $f(n) = \frac{lg(n^2)}{n}, g(n) = lg^*(n)$
	
		\[f(n) = \frac{lg(n^2)}{n} = \frac{2 lg(n)}{n}\]
		
		\[ f = \Theta(g) \]
		
	\item $f(n) = 2^n, g(n) = n^{\lg(n)}$
	
		This is comparing the exponential function to a function that is less than
		$n^2$.
		
		\[ f = \Omega(g) \]
		
	\item $f(n) = 2^{\sqrt{\ln(n)}}, g(n) = n(\lg(n)^3)$
	
		\[ f(n) = 2^{\sqrt{n}}, g(n) = (2^n) (n^3) \]
		
		\[f = \Omega{g}\]
	
	\item $f(n) = e^{\cos(x)}, g(n) = \lg(x)$
	
		\[ f = \Omega(g) \]
	
	\item $ f(n) = \lg(n^2), g(n) = (\lg(n))^2 $
	
		\[ f = \Theta(g) \]
	
	\item $ f(n) = \sqrt{4n^2 - 12n + 9}, g(n) = n^{\frac{3}{2}} $
	
		\[ f = \Theta(g) \]
	
	\item $ f(n) = \sum_{k = 1}^{n} k, g(n) = (n + 2)^2 $
	
		\[ f = \Omega(g) \]

\end{enumerate}

\subsection*{Problem 2}

\begin{algorithm}[h]
\caption{${\tt Number\_Theoretic\_Algorithm}$ $($ integer $n$ ) }
\label{algo}
$N \leftarrow Random\_Sample( 0, 2^n-1)$\; 
\If{ $N$ is even }
{
  $N \leftarrow N + 1$ \CommentSty{/* Worse case, N is odd, 2 ** N - 1. */} \; 
}
$m \leftarrow N \mod\ n$ \CommentSty{/* worse case same as n */} \; 
\For{ $j \leftarrow 0$ to $m$ }
{
  \If{ ${\tt Greatest\_Common\_Divisor}$( $j, N ) \neq 1$ }
  {
    return {\tt FALSE}; \CommentSty{/* GCD is O(n) */}
  }
  Compute $x,z$ so that $N - 1 = 2^z \cdot x$ and $x$ is odd\;
  $y_0 \leftarrow (N-1-j)^x \mod N$\;
  \For{ $i \leftarrow 1$ to $m$}
  {
    $y_i \leftarrow y_{i-1}^2 \mod N$ \;
    $y_i \leftarrow y_i + y_{i-1} \mod N$\;
  }
  \If{ {\tt Low\_Error\_Primality\_Test}($y_m$) == {\tt FALSE} }
  {
    return {\tt FALSE} \CommentSty{/* Naive primality test is O(sqrt(n)) */} \;
  }
}
return {\tt TRUE}\;
\end{algorithm}

Compute the asymptotic running time of the
above algorithm as a function of its input parameter, given:

\begin{itemize}
\item The running times of integer arithmetic operations (e.g.,
  multiplication of two large $n$-bit numbers is $O(n^2)$).
\item Assume that sampling a number $N$ is an operation linear to the
  number of bits needed to represent this number.
\end{itemize}

\noindent Do not just present the final result. For each line of
pseudo-code indicate the best running time for the corresponding
operation given current knowledge from lectures and recitations and
then show how the overall running time emerges.\\

%First line takes 1 to save and 1 to generate.
%The first if block check is 1 (mod by 2, check if 0) along with 1 for assignment %and (cost of add here) for addition.
%Line 4 takes: , (mod time) for mod and 1 for assignment
%Line 5, the loop lasts m times and for each sub line: the if check is GCD runtime, %the computation is (unknown), y0 is: (cost of mod + exponent)
%the inner loop is m-1 times, and then for both line 11/12 is (modular exponential %time). the last if check is hfthe time for primality test.

Worse case running $n$ operations with times $O(n)$, $O(n)$, and $O(\sqrt{n})$.

That's a run time of $O(2 n^2 + n^{\frac{3}{2}})$, resulting in big-O of $O(n^2)$.

\section*{Part B}

\subsection*{Problem 3}
\begin{itemize}
\item A tree with $m$ children is $\log_m^(N+1)-1$.

\item A perfect tree will only be changing based on the $m,m^\prime$ values. Whichever value is larger will run faster.

\item
\end{itemize}


\subsection*{Problem 4}
\begin{itemize}
\item I found out how to do this using a website, since I didn't understand how to from lecture ? $2^{902} \bmod 7$ We can find the original, $2 \bmod 7 = 2$ because $7$ doesn't go into $2$ at all. We can next square, finding $4 \bmod 7 = 4$. Divide exponent in half, $2^{451} \bmod 7$. Next we can do $4 \bmod 7 = 4$ again, and square. $16 \bmod 7 = 2$. Once again we cut our exponent, $2^{225} \bmod 7$. Now we have $4 \cdot 2 \bmod 7 \to 8 \bmod 7 = 1$. Next we square our other value, $4 \bmod 7 = 4$. We divide exponent again, $2^{112} \bmod 7$, and we do $16 \bmod 7 = 2$. Another cut, $2^{56} \bmod 7$. We can check $2^2 \bmod 7 = 4$. Another time we cut, $2^{28} \bmod 7$. We need to use previous value again, $16 \bmod 7 = 2$. $2^{14} \bmod 7$ from another cut, and we use $4 \bmod 7 = 4$. We can cut again, $2^7 \bmod 7$ and we use $4 \bmod 7 = 4$. We are almost done and use $2^3 \bmod 7$. We must check $8 \bmod 7 = 1$, and now we are on the final step. $2^1 \bmod 7 = 4$

\item $11 \bmod 120 = 121, 13 \bmod 45 = 91, 9 \bmod 11 = 45$. For the last one and third one I used Extended Euclidean Algorithm discussed in class. I also used $p_i = p_{i-2} - p_{i-1} q_{i-2} \bmod n$.


Third one: $35 \bmod 77 \to 77 = 2(35) + 7$ and $p_0 = 0$. Next, $35 = 5(7) + 0$ and $p_1 = 1$. However, this can't be solved.

Last one: $11 \bmod 1111 \to 1111 = 101(11) + 0$. This one can't be solved either because we were unable to get past the step, like the third one.

\item $\forall y \in [1,x-1]: \gcd(x,y) = 1$. If we want to find all of the modulo $x^m$ between $0,1,...,x^m -1$ then we can assume there are $m$ total modulo inverses to compute. An example is that there $x = 2, m = 2$ to keep it simple. This means that every number from $1 \to 1: \gcd(1,1) = 1$ which is correct. Now we need to find $0,...,2^2-1$ which becomes $0,...,3$. We have a total of $4$ numbers to modulo inverse. The running time to find is the amount multiplied by the time it takes to run the euclidean algorithm. There's a total of $x^m$ to find and the Extended Euclidean algorithm takes $\log(m^2)$. Our total runtime is $x^m \log(m^2)$.

\end{itemize}

\subsection*{Problem 5}

\section*{Part C}

\subsection*{Problem 6}

\begin{itemize}

\item The hash function for the family is definitely consistent because each item is only either $0,1$, and we are modding by the total amount of choices, but I'm not sure how to prove this other than by what was stated in class: $Pr = { h_\alpha(x) = h_\alpha(y)} = Pr { \sum_{i=1}^4 \alpha_i \cdot x_i = \sum_{i = 1}^4 \alpha_i \cdot y_i \bmod N} = Pr {\underbrace{\sum_{i=1}^3 \alpha_i (x_i - y_i) = \alpha_4 (y_4 - x_4 \bmod N)}_\text{given x, y and randomly picked a1,a2,a3: c is constant}}$. However, in this case this would be different because we have $0,1$ not $1,...,4$: $Pr = { h_\alpha(x) = h_\alpha(y)} = Pr { \sum_{i=1}^2 \alpha_i \cdot x_i = \sum_{i = 1}^2 \alpha_i \cdot y_i \bmod N} = Pr {\underbrace{\sum_{i=1}^1 \alpha_i (x_i - y_i) = \alpha_2 (y_2 - x_2 \bmod N)}_\text{given x, y and randomly picked a1: c is constant}}$.

\item 

\end{itemize}

\subsection*{Problem 7}

\section*{Part D}

\subsection*{Problem 8}

\subsection*{Problem 9}

\end{document}